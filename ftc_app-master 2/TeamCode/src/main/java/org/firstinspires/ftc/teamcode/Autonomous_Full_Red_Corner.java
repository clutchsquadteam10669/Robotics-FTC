
/* Copyright (c) 2017 FIRST. All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without modification,
 * are permitted (subject to the limitations in the disclaimer below) provided that
 * the following conditions are met:
 *
 * Redistributions of source code must retain the above copyright notice, this list
 * of conditions and the following disclaimer.
 *
 * Redistributions in binary form must reproduce the above copyright notice, this
 * list of conditions and the following disclaimer in the documentation and/or
 * other materials provided with the distribution.
 *
 * Neither the name of FIRST nor the names of its contributors may be used to endorse or
 * promote products derived from this software without specific prior written permission.
 *
 * NO EXPRESS OR IMPLIED LICENSES TO ANY PARTY'S PATENT RIGHTS ARE GRANTED BY THIS
 * LICENSE. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
 * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO,
 * THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE
 * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
 * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
 * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
 * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */
package org.firstinspires.ftc.teamcode;

import android.app.Activity;
import android.graphics.Color;
import android.view.View;

import com.qualcomm.robotcore.eventloop.opmode.Autonomous;
import com.qualcomm.robotcore.eventloop.opmode.LinearOpMode;
import com.qualcomm.robotcore.hardware.ColorSensor;
import com.qualcomm.robotcore.util.ElapsedTime;

import org.firstinspires.ftc.robotcontroller.external.samples.ConceptVuforiaNavigation;
import org.firstinspires.ftc.robotcore.external.ClassFactory;
import org.firstinspires.ftc.robotcore.external.matrices.OpenGLMatrix;
import org.firstinspires.ftc.robotcore.external.matrices.VectorF;
import org.firstinspires.ftc.robotcore.external.navigation.AngleUnit;
import org.firstinspires.ftc.robotcore.external.navigation.AxesOrder;
import org.firstinspires.ftc.robotcore.external.navigation.AxesReference;
import org.firstinspires.ftc.robotcore.external.navigation.Orientation;
import org.firstinspires.ftc.robotcore.external.navigation.RelicRecoveryVuMark;
import org.firstinspires.ftc.robotcore.external.navigation.VuMarkInstanceId;
import org.firstinspires.ftc.robotcore.external.navigation.VuforiaLocalizer;
import org.firstinspires.ftc.robotcore.external.navigation.VuforiaTrackable;
import org.firstinspires.ftc.robotcore.external.navigation.VuforiaTrackableDefaultListener;
import org.firstinspires.ftc.robotcore.external.navigation.VuforiaTrackables;

/**
 * This OpMode illustrates the basics of using the Vuforia engine to determine
 * the identity of Vuforia VuMarks encountered on the field. The code is structured as
 * a LinearOpMode. It shares much structure with {@link ConceptVuforiaNavigation}; we do not here
 * duplicate the core Vuforia documentation found there, but rather instead focus on the
 * differences between the use of Vuforia for navigation vs VuMark identification.
 *
 * @see ConceptVuforiaNavigation
 * @see VuforiaLocalizer
 * @see VuforiaTrackableDefaultListener
 * see  ftc_app/doc/tutorial/FTC_FieldCoordinateSystemDefinition.pdf
 *
 * Use Android Studio to Copy this Class, and Paste it into your team's code folder with a new name.
 * Remove or comment out the @Disabled line to add this opmode to the Driver Station OpMode list.
 *
 * IMPORTANT: In order to use this OpMode, you need to obtain your own Vuforia license key as
 * is explained in {@link ConceptVuforiaNavigation}.
 */

@Autonomous(name="Autonoumous RED CORNER", group ="Concept")
//@Disabled
public class Autonomous_Full_Red_Corner extends LinearOpMode {

    public static final String TAG = "Vuforia VuMark Sample";

    OpenGLMatrix lastLocation = null;
    static final double COUNTS_PER_MOTOR_REV = 1653;    // eg: Ou this is adjusted number for our robot 53.3 ticks per inch
    static final double DRIVE_GEAR_REDUCTION = 0.5;     // This is < 1.0 if geared UP
    static final double WHEEL_DIAMETER_INCHES = 4.0;     // For figuring circumference
    static final double COUNTS_PER_INCH = (COUNTS_PER_MOTOR_REV * DRIVE_GEAR_REDUCTION) /
            (WHEEL_DIAMETER_INCHES * 3.1415);
    static final double COUNTS_PER_MOTOR_STRAFE_REV = 2204;    // eg: Ou this is adjusted number for our robot 53.3 ticks per inch
    static final double COUNTS_PER_STRAFE_INCH = (COUNTS_PER_MOTOR_STRAFE_REV * DRIVE_GEAR_REDUCTION) /
            (WHEEL_DIAMETER_INCHES * 3.1415);
    static final double DRIVE_SPEED = 0.3;
    HardwarePushbotCustom20178 robot = new HardwarePushbotCustom20178();
    EncoderMethods Encoders  = new EncoderMethods();
    private ElapsedTime runtime = new ElapsedTime();
    double f = 0.2;
    double b = -0.2;
    ColorSensor colorSensor;

    /*
     * {@link #vuforia} is the variable we will use to store our instance of the Vuforia
     * localization engine.
     */
    VuforiaLocalizer vuforia;

    @Override public void runOpMode() throws InterruptedException {


        /*
         * To start up Vuforia, tell it the view that we wish to use for camera monitor (on the RC phone);
         * If no camera monitor is desired, use the parameterless constructor instead (commented out below).
         */
        robot.init(hardwareMap);
        float hsvValues[] = {0F, 0F, 0F};

        // values is a reference to the hsvValues array.
        final float values[] = hsvValues;

        // get a reference to the RelativeLayout so we can change the background
        // color of the Robot Controller app to match the hue detected by the RGB sensor.
        int relativeLayoutId = hardwareMap.appContext.getResources().getIdentifier("RelativeLayout", "id", hardwareMap.appContext.getPackageName());
        final View relativeLayout = ((Activity) hardwareMap.appContext).findViewById(relativeLayoutId);

        // bPrevState and bCurrState represent the previous and current state of the button.
        boolean bPrevState = false;
        boolean bCurrState = false;

        // bLedOn represents the state of the LED.
        boolean bLedOn = true;

        // get a reference to our ColorSensor object.
        colorSensor = hardwareMap.get(ColorSensor.class, "sensor_color");

        // Set the LED in the beginning
        colorSensor.enableLed(bLedOn);


        int cameraMonitorViewId = hardwareMap.appContext.getResources().getIdentifier("cameraMonitorViewId", "id", hardwareMap.appContext.getPackageName());
        VuforiaLocalizer.Parameters parameters = new VuforiaLocalizer.Parameters(cameraMonitorViewId);

        // OR...  Do Not Activate the Camera Monitor View, to save power
        //VuforiaLocalizer.Parameters parameters = new VuforiaLocalizer.Parameters();

        /*
         * IMPORTANT: You need to obtain your own license key to use Vuforia. The string below with which
         * 'parameters.vuforiaLicenseKey' is initialized is for illustration only, and will not function.
         * A Vuforia 'Development' license key, can be obtained free of charge from the Vuforia developer
         * web site at https://developer.vuforia.com/license-manager.
         *
         * Vuforia license keys are always 380 characters long, and look as if they contain mostly
         * random data. As an example, here is a example of a fragment of a valid key:
         *      ... yIgIzTqZ4mWjk9wd3cZO9T1axEqzuhxoGlfOOI2dRzKS4T0hQ8kT ...
         * Once you've obtained a license key, copy the string from the Vuforia web site
         * and paste it in to your code onthe next line, between the double quotes.
         */
        parameters.vuforiaLicenseKey = "AfprXUL/////AAAAGfY1xZ7or0lruQmUNSY4+LeBq0LGWrhvHG5HbKapX+MFc5SVVV4j2DBciNWGTmqmG7eIUk8VE30Eg+pmHdPaY1nhyMUa3dvzQqHMy4N7ddy/P63ZDPet4CjHrL2ny6oFVgv13CLUpu2mt/MiYlnPP6gcuY4Jdib8L9hOPCYeVb6gE/cnBUKV2ZhsMe5WekSJDHfIbeIX+ZecnA+mqIhrRs3u9tHXSjm5+a0NtAJMTHBI6kvpfUyU7ZyJkGCy1Yf62cPOXGH9nI7mmRvbDhSZMSQDpc0J1op1I2E3jMK8XSQG0WeMlz7iiliiADsx/Fno/8HilKlC4GJnJXPROyKmrru/OAO3ykj+8s9M0cuWaYnI";

        /*
         * We also indicate which camera on the RC that we wish to use.
         * Here we chose the back (HiRes) camera (for greater range), but
         * for a competition robot, the front camera might be more convenient.
         */
        parameters.cameraDirection = VuforiaLocalizer.CameraDirection.BACK;
        this.vuforia = ClassFactory.createVuforiaLocalizer(parameters);

        /**
         * Load the data set containing the VuMarks for Relic Recovery. There's only one trackable
         * in this data set: all three of the VuMarks in the game were created from this one template,
         * but differ in their instance id information.
         * @see VuMarkInstanceId
         */
        VuforiaTrackables relicTrackables = this.vuforia.loadTrackablesFromAsset("RelicVuMark");
        VuforiaTrackable relicTemplate = relicTrackables.get(0);
        relicTemplate.setName("relicVuMarkTemplate"); // can help in debugging; otherwise not necessary

        telemetry.addData(">", "Press Play to start");
        telemetry.update();
        waitForStart();

        relicTrackables.activate();

        if (opModeIsActive()) {
            // check the status of the x button on either gamepad.
            bCurrState = gamepad1.x;

            // check for button state transitions.
            if (bCurrState && (bCurrState != bPrevState)) {

                // button is transitioning to a pressed state. So Toggle LED
                bLedOn = !bLedOn;
                colorSensor.enableLed(bLedOn);
            }

            // update previous state variable.
            bPrevState = bCurrState;
            robot.leftArmHandle.setPosition(1.2);
            robot.rightArmHandle.setPosition(-0.61);
            robot.leftArmMotor.setPower(0.5);
            robot.rightArmMotor.setPower(0.5);
            sleep(500);
            robot.colorServo.setPosition(0.63);

            sleep(4000);
            // convert the RGB values to HSV values.
            Color.RGBToHSV(colorSensor.red() * 8, colorSensor.green() * 8, colorSensor.blue() * 8, hsvValues);

            // send the info back to driver station using telemetry function.
            telemetry.addData("LED", bLedOn ? "On" : "Off");
            telemetry.addData("Clear", colorSensor.alpha());
            telemetry.addData("Red", colorSensor.red());
            telemetry.addData("Green", colorSensor.green());
            telemetry.addData("Blue", colorSensor.blue());
            telemetry.addData("Hue", hsvValues[0]);

            // change the background color to match the color detected by the RGB sensor.
            // pass a reference to the hue, saturation, and value array as an argument
            // to the HSVToColor method.
            relativeLayout.post(new Runnable() {
                public void run() {
                    relativeLayout.setBackgroundColor(Color.HSVToColor(0xFF, values));

                }
            });
            telemetry.update();

            for(int i  =0 ; i  < 4; i++)
            {
                if (colorSensor.red() > 0 && colorSensor.blue() <= 0) //(colorSensor.red() == 255 && colorSensor.blue() == 255 && colorSensor.green() == 255)
                {
                    robot.colorServo.setPosition(0.63);
                    Encoders.encoderDrive(DRIVE_SPEED, 2.25, 2.25, 20);
                    robot.colorServo.setPosition(0.0);
                    Encoders.encoderDrive(DRIVE_SPEED, -2.25, -2.25, 20);
                    break;
                }
                else if (colorSensor.blue() > 0 && colorSensor.red() <= 0)//((colorSensor.red() == 0 && colorSensor.green() == 255 && colorSensor.blue() == 255) || (colorSensor.red() == 0 && colorSensor.green() >= 0 && colorSensor.blue() >= 0))
                {
                    robot.colorServo.setPosition(0.63);
                    Encoders.encoderDrive(DRIVE_SPEED, -2.25, -2.25, 20);
                    robot.colorServo.setPosition(0.0);
                    Encoders.encoderDrive(DRIVE_SPEED, 2.25, 2.25, 20);
                    break;
                }
                else
                {
                    robot.colorServo.setPosition(0.0);
                    sleep(750);
                    robot.colorServo.setPosition(0.63);
                    sleep(4000);
                    if ( i == 3)
                    {
                        robot.colorServo.setPosition(0.0);
                    }
                }
            }
//            encoderDrive(DRIVE_SPEED,32,32,20);
//           encoderIndDrive(DRIVE_SPEED,-10,10,-10,10,20);
//            encoderDrive(DRIVE_SPEED,5,5,20);
//            robot.leftArmHandle.setPosition(0);
//            robot.rightArmHandle.setPosition(1);
            robot.leftFrontMotor.setPower(0);
            robot.rightFrontMotor.setPower(0);
            robot.leftBackMotor.setPower(0);
            robot.rightBackMotor.setPower(0);
            robot.colorServo.setPosition(0.0);
            relativeLayout.post(new Runnable() {
                public void run() {
                    relativeLayout.setBackgroundColor(Color.WHITE);
                }
            });
            while (opModeIsActive() && (runtime.seconds() < 0.2)) {

                telemetry.addData("Path", "Leg 2: %2.5f S Elapsed", runtime.seconds());
                telemetry.update();
            }
        }
        while (opModeIsActive()) {
            RelicRecoveryVuMark vuMark = RelicRecoveryVuMark.from(relicTemplate);
            if (vuMark != RelicRecoveryVuMark.UNKNOWN) {

               /* Found an instance of the template. In the actual game, you will probably
                 * loop until this condition occurs, then move on to act accordingly depending
                 * on which VuMark was visible. */
                telemetry.addData("VuMark", "%s visible", vuMark);

                /* For fun, we also exhibit the navigational pose. In the Relic Recovery game,
                 * it is perhaps unlikely that you will actually need to act on this pose information, but
                 * we illustrate it nevertheless, for completeness. */
                OpenGLMatrix pose = ((VuforiaTrackableDefaultListener) relicTemplate.getListener()).getPose();
                telemetry.addData("Pose", format(pose));

                /* We further illustrate how to decompose the pose into useful rotational and
                 * translational components */
                if (pose != null)
                {
                    VectorF trans = pose.getTranslation();
                    Orientation rot = Orientation.getOrientation(pose, AxesReference.EXTRINSIC, AxesOrder.XYZ, AngleUnit.DEGREES);

                    // Extract the X, Y, and Z components of the offset of the target relative to the robot
                    double tX = trans.get(0);
                    double tY = trans.get(1);
                    double tZ = trans.get(2);

                    // Extract the rotational components of the target relative to the robot
                    double rX = rot.firstAngle;
                    double rY = rot.secondAngle;
                    double rZ = rot.thirdAngle;
                }
                if (vuMark == RelicRecoveryVuMark.LEFT)
                {
                    Encoders.encoderDrive(DRIVE_SPEED, -32.0, -32.0, 20);
                    Encoders.encoderIndDrive(DRIVE_SPEED,4.0,-4.0,-4.0,4.0,20);
                    robot.rightArmHandle.setPosition(1.0);
                    robot.leftArmHandle.setPosition(0.0);
                    Encoders.encoderDrive(DRIVE_SPEED, 2.0, 2.0, 20);
                }
                else if (vuMark == RelicRecoveryVuMark.CENTER)
                {
                    Encoders.encoderDrive(DRIVE_SPEED, -32.0, -32.0, 20);
                    Encoders.encoderIndDrive(DRIVE_SPEED,10.0,-10.0,-10.0,10.0,20);
                    robot.rightArmHandle.setPosition(1.0);
                    robot.rightArmHandle.setPosition(1.0);
                    robot.leftArmHandle.setPosition(0.0);
                    Encoders.encoderDrive(DRIVE_SPEED, 2.0, 2.0, 20);
                }
                else if (vuMark == RelicRecoveryVuMark.RIGHT)
                {
                    Encoders.encoderDrive(DRIVE_SPEED, -32.0, -32.0, 20);
                    Encoders.encoderIndDrive(DRIVE_SPEED,18.0,-18.0,-18.0,18.0,20);
                    robot.rightArmHandle.setPosition(1.0);
                    robot.rightArmHandle.setPosition(1.0);
                    robot.leftArmHandle.setPosition(0.0);
                    Encoders.encoderDrive(DRIVE_SPEED, 2.0, 2.0, 20);
                }
            }
            else
            {
                Encoders.encoderDrive(DRIVE_SPEED, -32.0, -32.0, 20);
                Encoders.encoderIndDrive(DRIVE_SPEED,18.0,-18.0,-18.0,18.0,20);
                robot.rightArmHandle.setPosition(1.0);
                robot.leftArmHandle.setPosition(0.0);
                Encoders.encoderDrive(DRIVE_SPEED, 2.0, 2.0, 20);
                telemetry.addData("VuMark", "not visible");
            }

            telemetry.update();

        }
        telemetry.addData("Path", "Complete");
        telemetry.update();
        sleep(1000);
    }
//    public void encoderDrive(double speed,
//                             double leftInches, double rightInches,
//                             double timeoutS) {
//        int newLeftFrontTarget;
//        int newRightFrontTarget;
//        int newLeftBackTarget;
//        int newRightBackTarget;
//
//        // Ensure that the opmode is still active
//        if (opModeIsActive()) {
//
//            // Determine new target position, and pass to motor controller
//            newLeftFrontTarget = robot.leftFrontMotor.getCurrentPosition() + (int) (leftInches * COUNTS_PER_INCH);
//            newRightFrontTarget = robot.rightFrontMotor.getCurrentPosition() + (int) (rightInches * COUNTS_PER_INCH);
//            newLeftBackTarget = robot.leftBackMotor.getCurrentPosition() + (int) (leftInches * COUNTS_PER_INCH);
//            newRightBackTarget = robot.rightBackMotor.getCurrentPosition() + (int) (rightInches * COUNTS_PER_INCH);
//            robot.leftFrontMotor.setTargetPosition(newLeftFrontTarget);
//            robot.rightFrontMotor.setTargetPosition(newRightFrontTarget);
//            robot.leftBackMotor.setTargetPosition(newLeftBackTarget);
//            robot.rightBackMotor.setTargetPosition(newRightBackTarget);
//
//            // Turn On RUN_TO_POSITION
//            robot.leftFrontMotor.setMode(DcMotor.RunMode.RUN_TO_POSITION);
//            robot.rightFrontMotor.setMode(DcMotor.RunMode.RUN_TO_POSITION);
//            robot.leftBackMotor.setMode(DcMotor.RunMode.RUN_TO_POSITION);
//            robot.rightBackMotor.setMode(DcMotor.RunMode.RUN_TO_POSITION);
//
//            // reset the timeout time and start motion.
//            runtime.reset();
//            robot.leftFrontMotor.setPower(Math.abs(speed));
//            robot.rightFrontMotor.setPower(Math.abs(speed));
//            robot.leftBackMotor.setPower(Math.abs(speed));
//            robot.rightBackMotor.setPower(Math.abs(speed));
//
//            // keep looping while we are still active, and there is time left, and both motors are running.
//            while (opModeIsActive() &&
//                    (runtime.seconds() < timeoutS) &&
//                    (robot.leftFrontMotor.isBusy() && robot.rightFrontMotor.isBusy() && robot.rightBackMotor.isBusy() && robot.leftBackMotor.isBusy())) {
//
//                // Display it for the driver.
//                telemetry.addData("Path1", "Running to %7d :%7d", newLeftFrontTarget, newRightFrontTarget, newLeftBackTarget, newRightBackTarget);
//                telemetry.addData("Path2", "Running at %7d :%7d",
//                        robot.leftFrontMotor.getCurrentPosition(),
//                        robot.rightFrontMotor.getCurrentPosition(),
//                        robot.leftBackMotor.getCurrentPosition(),
//                        robot.rightBackMotor.getCurrentPosition());
//                telemetry.update();
//            }
//
//            // Stop all motion;
//            robot.leftFrontMotor.setPower(0);
//            robot.rightFrontMotor.setPower(0);
//            robot.leftBackMotor.setPower(0);
//            robot.rightBackMotor.setPower(0);
//
//            // Turn off RUN_TO_POSITION
//            robot.leftFrontMotor.setMode(DcMotor.RunMode.RUN_USING_ENCODER);
//            robot.rightFrontMotor.setMode(DcMotor.RunMode.RUN_USING_ENCODER);
//            robot.leftBackMotor.setMode(DcMotor.RunMode.RUN_USING_ENCODER);
//            robot.rightBackMotor.setMode(DcMotor.RunMode.RUN_USING_ENCODER);
//
//            //  sleep(250);   // optional pause after each move
//        }
//    }
//    public void encoderIndDrive(double speed,
//                                double leftBackInches,double leftFrontInches,  double rightFrontInches,
//                                double rightBackInches,
//                                double timeoutS) {
//        int newLeftFrontTarget;
//        int newRightFrontTarget;
//        int newLeftBackTarget;
//        int newRightBackTarget;
//
//        // Ensure that the opmode is still active
//        if (opModeIsActive()) {
//
//            // Determine new target position, and pass to motor controller
//            newLeftFrontTarget = robot.leftFrontMotor.getCurrentPosition() + (int) (leftFrontInches * COUNTS_PER_STRAFE_INCH);
//            newRightFrontTarget = robot.rightFrontMotor.getCurrentPosition() + (int) (rightFrontInches * COUNTS_PER_STRAFE_INCH);
//            newLeftBackTarget = robot.leftBackMotor.getCurrentPosition() + (int) (leftBackInches * COUNTS_PER_STRAFE_INCH);
//            newRightBackTarget = robot.rightBackMotor.getCurrentPosition() + (int) (rightBackInches * COUNTS_PER_STRAFE_INCH);
//            robot.leftFrontMotor.setTargetPosition(newLeftFrontTarget);
//            robot.rightFrontMotor.setTargetPosition(newRightFrontTarget);
//            robot.leftBackMotor.setTargetPosition(newLeftBackTarget);
//            robot.rightBackMotor.setTargetPosition(newRightBackTarget);
//
//            // Turn On RUN_TO_POSITION
//            robot.leftFrontMotor.setMode(DcMotor.RunMode.RUN_TO_POSITION);
//            robot.rightFrontMotor.setMode(DcMotor.RunMode.RUN_TO_POSITION);
//            robot.leftBackMotor.setMode(DcMotor.RunMode.RUN_TO_POSITION);
//            robot.rightBackMotor.setMode(DcMotor.RunMode.RUN_TO_POSITION);
//
//            // reset the timeout time and start motion.
//            runtime.reset();
//            robot.leftFrontMotor.setPower(Math.abs(speed));
//            robot.rightFrontMotor.setPower(Math.abs(speed));
//            robot.leftBackMotor.setPower(Math.abs(speed));
//            robot.rightBackMotor.setPower(Math.abs(speed));
//
//            // keep looping while we are still active, and there is time left, and both motors are running.
//            while (opModeIsActive() &&
//                    (runtime.seconds() < timeoutS) &&
//                    (robot.leftFrontMotor.isBusy() && robot.rightFrontMotor.isBusy() && robot.rightBackMotor.isBusy() && robot.leftBackMotor.isBusy())) {
//
//                // Display it for the driver.
//                telemetry.addData("Path1", "Running to %7d :%7d", newLeftFrontTarget, newRightFrontTarget, newLeftBackTarget, newRightBackTarget);
//                telemetry.addData("Path2", "Running at %7d :%7d",
//                        robot.leftFrontMotor.getCurrentPosition(),
//                        robot.rightFrontMotor.getCurrentPosition(),
//                        robot.leftBackMotor.getCurrentPosition(),
//                        robot.rightBackMotor.getCurrentPosition());
//                telemetry.update();
//            }
//
//            // Stop all motion;
//            robot.leftFrontMotor.setPower(0);
//            robot.rightFrontMotor.setPower(0);
//            robot.leftBackMotor.setPower(0);
//            robot.rightBackMotor.setPower(0);
//
//            // Turn off RUN_TO_POSITION
//            robot.leftFrontMotor.setMode(DcMotor.RunMode.RUN_USING_ENCODER);
//            robot.rightFrontMotor.setMode(DcMotor.RunMode.RUN_USING_ENCODER);
//            robot.leftBackMotor.setMode(DcMotor.RunMode.RUN_USING_ENCODER);
//            robot.rightBackMotor.setMode(DcMotor.RunMode.RUN_USING_ENCODER);
//
//            //  sleep(250);   // optional pause after each move
//        }
//    }
    String format(OpenGLMatrix transformationMatrix) {
        return (transformationMatrix != null) ? transformationMatrix.formatAsTransform() : "null";
    }
}
